{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chapter', 'i'], ['prejudices', 'of', 'philosophers', 'the', 'will', 'to', 'truth', 'which', 'is', 'to', 'tempt', 'us', 'to', 'many', 'a', 'hazardous', 'enterprise', 'the', 'famous', 'truthfulness', 'of', 'which', 'all', 'philosophers', 'have', 'hitherto', 'spoken', 'with', 'respect', 'what', 'questions', 'has', 'this', 'will', 'to', 'truth', 'not', 'laid', 'before', 'us'], ['what', 'strange', 'perplexing', 'questionable', 'questions'], ['it', 'is', 'already', 'a', 'long', 'story', 'yet', 'it', 'seems', 'as', 'if', 'it', 'were', 'hardly', 'commenced'], ['is', 'it', 'any', 'wonder', 'if', 'we', 'at', 'last', 'grow', 'distrustful', 'lose', 'patience', 'and', 'turn', 'impatiently', 'away']]\n"
     ]
    }
   ],
   "source": [
    "data_files = ['Beyond good and Evil.txt',\n",
    "              'The Birth of Tragedy.txt',\n",
    "              'On the Genealogy of Morality.txt',\n",
    "              'Thus Spoke Zarathustra.txt',\n",
    "              'The Antichrist.txt']\n",
    "book_names = ['Beyond good and Evil',\n",
    "              'The Birth of Tragedy',\n",
    "              'On the Genealogy of Morality',\n",
    "              'Thus Spoke Zarathustra',\n",
    "              'The Antichrist']\n",
    "class_count = len(data_files)\n",
    "\n",
    "data_lines =[]\n",
    "for file in data_files:\n",
    "    path = 'datasets/{}'.format(file)\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    data_lines.append(lines)\n",
    "    \n",
    "data_strings = [\" \".join(d).replace(\"\\n\",\"\") for d in data_lines]\n",
    "data_sentences = []\n",
    "for st in data_strings:\n",
    "    st = re.sub(\"[^a-zA-Z0-9\\.\\?\\! ]\", \"\", st)\n",
    "    st = re.sub(\"\\d+\\.\", \"\", st)\n",
    "    sentences = re.split(\"\\. |\\! |\\?\", st)\n",
    "    data_sentences.append([[elem.lower() for elem in sent.split(\" \") if elem != \"\"] for sent in sentences])\n",
    "    \n",
    "print(data_sentences[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8330\n",
      "bone\n",
      "22723\n"
     ]
    }
   ],
   "source": [
    "index2word = [\"<UNK>\"]+list(set([word for book in data_sentences for sent in book for word in sent]))\n",
    "word2index_ = defaultdict(int)\n",
    "i = 0\n",
    "for word in index2word:\n",
    "    word2index_[word] = i\n",
    "    i+=1\n",
    "def word2index(word):\n",
    "    if word in word2index_.keys():\n",
    "        return word2index_[word]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vocab_size = len(index2word)\n",
    "\n",
    "print(word2index('bone'))\n",
    "print(index2word[word2index('bone')])\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 0., ..., 0., 0., 0.]), 0)\n"
     ]
    }
   ],
   "source": [
    "# word indices per sentence per book\n",
    "data_sentences_indices = [\n",
    "    [[word2index(word) for word in sent] for sent in book]\n",
    "    for book in data_sentences]\n",
    "\n",
    "# many-hot sentence representation, book index\n",
    "data = []\n",
    "for book_index in range(len(data_sentences_indices)):\n",
    "    for word_indices in data_sentences_indices[book_index]:\n",
    "        manyhot = np.zeros(vocab_size)\n",
    "        manyhot[word_indices] = 1\n",
    "        data.append((manyhot, book_index))\n",
    "        \n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data set\n",
    "random.shuffle(data)\n",
    "\n",
    "# segregate data\n",
    "data_size = len(data)\n",
    "data_train = data[:int(data_size*.9)]\n",
    "data_test = data[int(data_size*.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # neural network with two fully connected layers\n",
    "        self.fc1 = nn.Linear(vocab_size, 20)\n",
    "        self.fc2 = nn.Linear(20, len(book_names))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (fc1): Linear(in_features=22723, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n",
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silvan/Projects/Virtual_Nietzsche/nietz/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Starting epoch 8\n",
      "Starting epoch 9\n"
     ]
    }
   ],
   "source": [
    "net = Classifier()\n",
    "print(net)\n",
    "\n",
    "optimiser = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(\"Starting epoch {}\".format(epoch))\n",
    "    for x,t in data_train:\n",
    "        inp = torch.from_numpy(x).float()\n",
    "        target = torch.zeros(class_count)\n",
    "        target[t] = 1\n",
    "        optimiser.zero_grad()\n",
    "        output = net(inp)\n",
    "        loss = criterion(F.softmax(output), target)\n",
    "        loss.backward()\n",
    "        optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    total = len(data_test)\n",
    "    total_correct = 0\n",
    "    correct_per_class = np.zeros(class_count)\n",
    "    total_per_class = np.zeros(class_count)\n",
    "    for x,t in data_test:\n",
    "        inp = torch.from_numpy(x).float()\n",
    "        output = model(inp).detach()\n",
    "        total_correct += 1 if np.argmax(output) == t else 0\n",
    "        total_per_class[t] += 1\n",
    "        correct_per_class[t] += 1 if np.argmax(output) == t else 0\n",
    "    accuracy = total_correct / total\n",
    "#     accuracy_per_class = correct_per_class / total_per_class\n",
    "    return accuracy, correct_per_class, total_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the sentence to book classifier is 65.48%\n",
      "Accuracy per book:\n",
      "\tBeyond good and Evil: 28% (41/145)\n",
      "\tThe Birth of Tragedy: 57% (86/151)\n",
      "\tOn the Genealogy of Morality: 0% (0/130)\n",
      "\tThus Spoke Zarathustra: 99% (666/674)\n",
      "\tThe Antichrist: 0% (0/111)\n"
     ]
    }
   ],
   "source": [
    "acc, class_cor, class_tot = test(net)\n",
    "print(\"The accuracy of the sentence to book classifier is {:.02f}%\".format(acc*100))\n",
    "print(\"Accuracy per book:\")\n",
    "class_acc = class_cor / class_tot\n",
    "for i in range(class_count):\n",
    "    print(\"\\t{}: {:.0f}% ({:d}/{:d})\".format(book_names[i],class_acc[i]*100, int(class_cor[i]),int(class_tot[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2manyhot(sentence):\n",
    "    # filter characters\n",
    "    indices = [word2index(word.lower()) for word in sentence.split(\" \")]\n",
    "    # many-hot representation\n",
    "    manyhot = np.zeros(vocab_size)\n",
    "    manyhot[indices] = 1\n",
    "    return torch.from_numpy(manyhot)\n",
    "\n",
    "def predict(model, sentence):\n",
    "    manyhot = sentence2manyhot(sentence).float()\n",
    "    output = model(manyhot).detach()\n",
    "    return book_names[np.argmax(output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"Superman\" fits best in Thus Spoke Zarathustra.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"A few weeks later: and he found himself under the walls of Metz, still wrestling with the notes of interrogation he had set down concerning the alleged cheerfulness of the Greeks and of Greek art; till at last, in that month of deep suspense, when peace was debated at Versailles, he too attained to peace with himself, and, slowly recovering from a disease brought home from the field, made up his mind definitely regarding the Birth of Tragedy from the Spirit of _Music\"\n",
    "\n",
    "print(\"The sentence \\\"{}\\\" fits best in {}.\".format(sentence, predict(net, sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
